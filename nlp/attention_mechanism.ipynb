{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSwJ2b7qTRG4UWU4FfBETv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swethag04/ml-projects/blob/main/nlp/attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Mechanism**\n",
        "\n",
        "* Simplified self attention\n",
        "* Self attention with trainable weights\n",
        "* Causal attention (consider only previous and current inputs in a sequence)\n",
        "* Multi head attention (Enables model to simultaneously attend to information from different representation subspaces)"
      ],
      "metadata": {
        "id": "Y_unrbmFPkv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing simple self attention** <br>\n",
        "The goal of self attention is to compute a context vector z, for each input element, that combines information from all other input elements. The importance of each element for computing z is determined by the attention weights . The attention weights are calculated with respect to input element and all other inputs."
      ],
      "metadata": {
        "id": "g80GJMTcQkgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Vhfc0TZfO7aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "AWRb24mIwNLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vector z2 using the second input sequence x2 as query\n",
        "# attn scores are computed by the dot product og the query with every other input token\n",
        "query = inputs[1]\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] =  torch.dot(x_i, query)\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YZb9UpkPq9D",
        "outputId": "53e6a679-40a4-46b3-aecb-f96a5f948b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After computing attentions cores, the next step is to compute the attention weights by normalizing the attention scores. The reason for normalization is to obtain attention weights that sum up to 1."
      ],
      "metadata": {
        "id": "Fzf15mgBPyIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2/attn_scores_2.sum()\n",
        "print(\"Attention weights: \", attn_weights_2_tmp)\n",
        "print(\"Sum: \", attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPPc_UKvR3Y-",
        "outputId": "882fe338-c9cc-48ba-cb07-58cbff46dc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:  tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum:  tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is more common to use softmax function for normalization as it is a better approach to manage extreme values."
      ],
      "metadata": {
        "id": "gk2bG7UsSucx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "print(\"Attention weights:\" , attn_weights_2_naive)\n",
        "print(\"Sum:\" , attn_weights_2_naive.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPu9wQyvSqRY",
        "outputId": "7a4794da-b27e-4e40-ed00-8e916f8602ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using pytorch softmax implementation\n",
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "print(\"Attention weights: \", attn_weights_2)\n",
        "print(\"Sum: \", attn_weights_2.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMyM8OGITM-Z",
        "outputId": "fe23ac72-bbc1-4c84-c3af-7226ec52eca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final step is to compute the context vector, which is a weighted sum of all input vectors. This involves multiplying each input vectir by its corresponding attention weight."
      ],
      "metadata": {
        "id": "Lbfmcj4vTnu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_2[i]*x_i\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPIJSEnATjaG",
        "outputId": "3d36f730-554f-4902-b0c9-c25b414992df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing attention weights for all input tokens**"
      ],
      "metadata": {
        "id": "KDjXYbgGUfxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6,6)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i,j] = torch.dot(x_i, x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF22kjRNT8yd",
        "outputId": "c94ee91e-b621-45a4-f5bd-bd3b3ba88d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usign matrix mul for above\n",
        "attn_score = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQAt02QBU-uz",
        "outputId": "51168599-bb07-4f42-ca19-e9c4994f250d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frCYiTQ5VQyX",
        "outputId": "6c542cda-09b4-4afa-ee58-027bc8c0d2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All row sums:\", attn_weights.sum(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dBf1UoCVcBR",
        "outputId": "6fa2be89-161c-4d89-ef81-41542b20cdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vector via matrix multiplication\n",
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdzvbyJzVsmh",
        "outputId": "5652af75-7f89-4115-9e3a-36ae9a316f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing self attention with trainable weights** <br>\n",
        "Self attention with trainable weights is the mechanism used in original transformer, GPT models and most popular LLMs. This mechanism is also called as scaled dot product attention."
      ],
      "metadata": {
        "id": "DxnNA8GIWLfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1]\n",
        "\n",
        "# input embedding size\n",
        "d_in = inputs.shape[1]\n",
        "\n",
        "# output embedding size\n",
        "d_out=2"
      ],
      "metadata": {
        "id": "zcX1dpIZV3ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing three weight matrices\n",
        "torch.manual_seed(123)\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n"
      ],
      "metadata": {
        "id": "qvOI_agm0Tq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWpK6DS80bn4",
        "outputId": "b9169490-0409-4fc0-f142-10c892b2fc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4306, 1.4551])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the weight matrices, weight refers to the values of a neural network that are optimized during training. This is different from attention weights. Weight parameters are learned coffecients that define the network's connections, while attention weights are dynamic, context specific values."
      ],
      "metadata": {
        "id": "gSuii4wy0wov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxnMTYpQ0phi",
        "outputId": "b0f022be-7236-4e6d-b918-fdef67f32988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 6 input tokens have been projected from a 3D onto a 2D embedding space"
      ],
      "metadata": {
        "id": "Hj7J4viCce8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# attention score is the dot product between query and key vectors\n",
        "keys_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6LkVCQI1Tvw",
        "outputId": "7250828b-892c-4e19-cb71-698b9588afcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All attention scores for a given query\n",
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olgXQrDO1f-n",
        "outputId": "26cf663c-78b0-4990-8fe6-42db6197a552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attention weights\n",
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2/d_k**0.5, dim=-1)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cv6HEqW1pnT",
        "outputId": "cd607715-379e-4c40-861b-f633bc15e42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xzbjtyx13fb",
        "outputId": "514ea146-64bd-4f8f-e348-df633481d07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A query represents a current item (e.g. a word or token in a sentence) the model focuses on or tries to understand. The query is used to probe the other parts of the input sequence to determine how much attention to pay to them. <br>\n",
        "\n",
        "The key is like a database key used for indexing and searching. In the attention mechanism, each item in the input sequence has an associated key. These keys are used to match with the query. <br>\n",
        "\n",
        "The value represents the actual content or representation of input items. Once the model determines which keys are mose relevant to the query, it retrieves the corresponding values.\n",
        "\n"
      ],
      "metadata": {
        "id": "_YSX2_mnJNn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## A compact self attention class\n",
        "import torch.nn as nn\n",
        "class SelfAttention_v1(nn.Module): ## derived class from nn.Module\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self,x):\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @self.W_query\n",
        "    values = x @ self.W_value\n",
        "    attn_scores = queries @keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "                      attn_scores/keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "XdyorheB2Eo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4XOd1NOLBv1",
        "outputId": "d11b81d0-fafc-442e-f0ce-43947bd42251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In self-attention, we transform the input vectors in the input matrix X with the three weight matrices, Wq, Wk, and Wv. Then, we compute the attention weight matrix based on the resulting queries (Q) and keys (K). Using the attention weights and values (V), we then compute the context vectors (Z)."
      ],
      "metadata": {
        "id": "6uXUj94jMK9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Self attention class using Pytorch's linear layers\n",
        "\n",
        "class SelfAttention_v2(nn.Module):\n",
        "  def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim=1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n"
      ],
      "metadata": {
        "id": "sPBCYq2QLZkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Causal attention or masked attention is a specialized form of self attention. It restricts a model to only consider previous and current inputs in a sequence when processing any given token."
      ],
      "metadata": {
        "id": "MNaUVzkNNiE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76AFR9drO9pL",
        "outputId": "f32b5d22-74b7-4eaa-9877-3264150a38b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5337, -0.1051],\n",
            "        [-0.5323, -0.1080],\n",
            "        [-0.5323, -0.1079],\n",
            "        [-0.5297, -0.1076],\n",
            "        [-0.5311, -0.1066],\n",
            "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBo0xM_TNMe4",
        "outputId": "40fec133-7776-405e-9907-b64d4506a160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
            "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
            "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
            "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
            "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(block_size, block_size))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAkM12OZOZn_",
        "outputId": "54fda332-e5a1-402c-bdcc-6ad6ac29302b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights * mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz10iFf2B1Vp",
        "outputId": "457e886a-d658-41fc-91b6-c4a59727d4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izB3XIVICDzV",
        "outputId": "54a927fc-7846-4ddd-fc35-1aa3d8aa2777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
            "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(block_size, block_size), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdW8MVeJCZMG",
        "outputId": "6dce081e-d0f2-42b2-fd06-8d5b2d54a5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3111,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.1655, 0.2602,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.1667, 0.2602, 0.2577,   -inf,   -inf,   -inf],\n",
            "        [0.0510, 0.1080, 0.1064, 0.0643,   -inf,   -inf],\n",
            "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121,   -inf],\n",
            "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked/keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2eaUm2_Dx9O",
        "outputId": "6ed77876-5084-413c-ad64-dfcf1efe4ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
            "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5)\n",
        "example = torch.ones(6,6)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S5ujr11EgpI",
        "outputId": "71184eeb-7779-4d6d-d747-97d68b21d5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHIBdYvFFpIn",
        "outputId": "09de1734-f9a5-4cf4-9c3f-633c6492522a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 1.0335, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6804, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4889, 0.5090, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3988, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3418, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUc1qeRqGZXb",
        "outputId": "535e2750-c1a7-46c9-91c9-3667e6f8aeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Causal attention class\n",
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, block_size, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "          'mask',\n",
        "          torch.triu(torch.ones(block_size, block_size),diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1,2)\n",
        "    attn_scores.masked_fill_(\n",
        "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n"
      ],
      "metadata": {
        "id": "96xteQ4dGdcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "block_size = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, block_size, 0.0)\n",
        "context_vecs = ca(batch)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)\n",
        "context_vecs.shape: torch.Size([2, 6, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYBn4YkhJJDX",
        "outputId": "b7ec9b5f-c87e-4404-a3d5-1ee1053c793a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi headed attention:\n",
        "Implementing multi head attention involves creating multiple instances of the self-attention mechanism, each with its own weights and then combining their outputs.\n"
      ],
      "metadata": {
        "id": "Qu9vH1P8LPaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper class to implement multi head attention:\n",
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out, block_size,\n",
        "               dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [CausalAttention(d_in, d_out, block_size, dropout,qkv_bias)\n",
        "         for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "90D6M4pWJfce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "block_size = batch.shape[1]\n",
        "d_in, d_out = 3,2\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out, block_size, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3hvKcZKMQ_b",
        "outputId": "05bfdd54-1a19-4abf-e0b7-89d30e89236d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0844,  0.0414,  0.0766,  0.0171],\n",
            "         [-0.2264, -0.0039,  0.2143,  0.1185],\n",
            "         [-0.4163, -0.0564,  0.3878,  0.2453],\n",
            "         [-0.5014, -0.1011,  0.4992,  0.3401],\n",
            "         [-0.7754, -0.1867,  0.7387,  0.4868],\n",
            "         [-1.1632, -0.3303,  1.1224,  0.8460]],\n",
            "\n",
            "        [[-0.0844,  0.0414,  0.0766,  0.0171],\n",
            "         [-0.2264, -0.0039,  0.2143,  0.1185],\n",
            "         [-0.4163, -0.0564,  0.3878,  0.2453],\n",
            "         [-0.5014, -0.1011,  0.4992,  0.3401],\n",
            "         [-0.7754, -0.1867,  0.7387,  0.4868],\n",
            "         [-1.1632, -0.3303,  1.1224,  0.8460]]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An efficient multi head attention class\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out,\n",
        "                 block_size, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            'mask',\n",
        "             torch.triu(torch.ones(block_size, block_size), diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        mask_unsqueezed = mask_bool.unsqueeze(0).unsqueeze(0)\n",
        "        attn_scores.masked_fill_(mask_unsqueezed, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "CwfKTbhYNGNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "batch_size, block_size, d_in = batch.shape\n",
        "d_out = 2\n",
        "mha = MultiHeadAttention(d_in, d_out, block_size, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzNfrmA4NfVQ",
        "outputId": "c977daad-1396-43d1-9880-1108971d4912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]],\n",
            "\n",
            "        [[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckn89KtyN647"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}